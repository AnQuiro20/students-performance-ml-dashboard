# ğŸ“Š Students Performance â€“ Machine Learning Dashboard

![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)
![Scikit-Learn](https://img.shields.io/badge/Scikit--Learn-ML-orange)
![Streamlit](https://img.shields.io/badge/Streamlit-Dashboard-red)
![Status](https://img.shields.io/badge/Status-Active-success)

End-to-End Machine Learning project where I analyze academic performance data and build predictive models to estimate math scores using explainable AI techniques.

---

## ğŸ‘¨â€ğŸ’» About Me

**AndrÃ©s QuirÃ³s Rojas**  
Computer Engineering Student  
Instituto TecnolÃ³gico de Costa Rica  

---

## ğŸ¯ Project Objective

The objective of this project is to simulate a real-world Machine Learning pipeline by:

- Performing Exploratory Data Analysis (EDA)
- Building preprocessing pipelines
- Comparing regression models
- Applying cross-validation
- Interpreting model behavior using SHAP
- Deploying an interactive dashboard with Streamlit
- Generating automated PDF performance reports

---

## ğŸ“Š Dataset

**Dataset:** Students Performance Dataset  

### ğŸ¯ Target Variable
- `math score`

### ğŸ“Œ Predictor Variables
- Reading score  
- Writing score  
- Gender  
- Parental level of education  
- Lunch type  
- Test preparation course  

---

## ğŸ§  Machine Learning Pipeline

### ğŸ”¹ Data Preprocessing

- Train/Test Split (80/20)
- ColumnTransformer
- StandardScaler (numerical features)
- OneHotEncoder (categorical features)
- 5-Fold Cross Validation

### ğŸ”¹ Models Implemented

- Linear Regression  
- Random Forest Regressor  

### ğŸ”¹ Evaluation Metrics

Each model is evaluated using:

- RÂ² Score  
- MAE (Mean Absolute Error)  
- RMSE (Root Mean Squared Error)  
- Cross-Validation Mean RÂ²  

---

## ğŸ“ˆ Model Interpretability

To ensure transparency and explainability:

- Feature Importance (Random Forest)
- SHAP values analysis
- Actual vs Predicted comparison plots

This allows better understanding of how different variables impact student performance predictions.

---

## ğŸ“Œ Key Insights

- Reading and writing scores are the strongest predictors of math performance.
- Students who completed test preparation courses tend to perform better.
- Socioeconomic indicators (lunch type) influence academic outcomes.
- SHAP confirms the relevance and contribution of main predictive features.

---

## ğŸ—ï¸ Project Structure

```
students-performance-ml-dashboard/
â”‚
â”œâ”€â”€ app.py              # Streamlit dashboard
â”œâ”€â”€ eda.py              # Exploratory analysis functions
â”œâ”€â”€ ml.py               # ML pipeline and model comparison
â”œâ”€â”€ utils.py            # Logging and dataset loading
â”œâ”€â”€ report.py           # Automated PDF report generation
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ StudentsPerformance.csv
â””â”€â”€ README.md
```

---

## ğŸš€ How to Run

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/anquiro20/students-performance-ml-dashboard.git
cd students-performance-ml-dashboard
```

### 2ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Run the application

```bash
streamlit run app.py
```

The dashboard will open locally in your browser.

---

## ğŸ› ï¸ Technologies Used

- Python  
- Pandas  
- NumPy  
- Scikit-learn  
- SHAP  
- Plotly  
- Streamlit  
- ReportLab  

---

## ğŸ’¡ What This Project Demonstrates

Through this project, I demonstrate my ability to:

- Design modular Machine Learning architectures  
- Apply structured preprocessing pipelines  
- Compare and evaluate regression models properly  
- Use explainable AI techniques  
- Build interactive dashboards  
- Translate technical results into actionable insights  

---

## ğŸ”® Future Improvements

- Hyperparameter tuning (GridSearchCV / RandomizedSearchCV)  
- Model persistence using joblib  
- Cloud deployment (Streamlit Cloud / Render)  
- Docker containerization  
- Testing with larger and more complex datasets  

---

## ğŸ“¬ Contact

If you would like to connect or discuss this project, feel free to reach out.
